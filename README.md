# üåï Mercury 
![Badge Linguagem](https://img.shields.io/badge/Linguagem-Python-blue)
![Badge Framework](https://img.shields.io/badge/biblioteca-Pandas-yellow)
![Badge DB](https://img.shields.io/badge/DB-PostgreSQL-blue)
![Badge API](https://img.shields.io/badge/API-Spotipy-green)
![Badge Status](https://img.shields.io/badge/Status-Done-G)
### Spotify ETL Job
Projeto desenvolvido para praticar aprendizados do curso **Design e Modelagem de Data Warehouses** da Data Science Academy. Mais informa√ß√µes no [PDF](https://github.com/Gabriel-SSD/Mercury/blob/main/files/mercury.pdf)

## Sobre a ETL:
O script principal que realiza o processo de ETL √© o etl.py, ele realiza a extra√ß√£o de dados da fonte, filtra e chama stored procedures que realizam transforma√ß√µes. Todas as procedures est√£o em scripts, assim como os scripts de cria√ß√£o do BD. Al√©m disso existem scripts adicionais em /aux, que definem configura√ß√µes de vari√°veis de ambiente, fun√ß√µes compartilhadas e backup dos dados. Todos os principais scripts registram seus logs em /logs.
### Passo a passo l√≥gico de etl.py
1. Extra√ß√£o de dados em lotes consumindo a API do Spotify, obtendo dados referentes √†s ultimas m√∫sicas escutadas em determinado per√≠odo, a partir desse retorno s√£o obtidos os ids de: track, album, artista e o timestamp da escuta.
2. A partir dos ids, s√£o filtrados apenas os ids √∫nicos, para reduzir chamadas aos endpoints na etapa 4.
3. Dependendo do volume de dados, √© necess√°rio separar em lotes, pois a API possui limita√ß√µes de ids por chamada.
4. Com os ids √∫nicos, realizam-se consultas nos respectivos endpoints para obter os dados relacionados aos artistas, tracks e album.
5. Os dados iniciais da primeira extra√ß√£o correspondem a tabela fato, as consultas derivadas da etapa anterior correspondem a dimens√µes, todos os dataframes s√£o gravados na stage para tratamento.
6. Dentro da stage, s√£o executadas stored procedures que tratam os dados, lidam com inconsist√™ncias da fonte e padronizam para serem gravados (upsert) dentro do Data Warehouse.
7. Ap√≥s o processo os dados se encontram limpos, organizados e estruturados no Data Warehouse dispon√≠vel para utiliza√ß√£o no Metabase.
